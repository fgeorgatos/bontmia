#!/bin/bash
#
# bontmia (Backup Over Network To Multiple Incremental Archives)
#
# This was written to get the functionality of glastree (Jeremy Wohl)
# available to use towards remote hosts and having a selective long
# term storage.
#
# Written by John Enok Vollestad in April 2003 and have later
# undergone some bugfixes and enhancements.

print_usage()
{
    cat <<EOF | more

NAME
        Bontmia - Backup Over Network To Multiple Incremental Archives
        Version 0.11

SYNOPSIS
        bontmia --dest <dest. dir> [options] [--source <source dirs>]

DESCRIPTION
        Bontmia is a network-based backup tool that saves configurable
        numbers of last month, week, day, hour, and minute backups.
        Each backup is a complete snapshot of the original
        directories.  Only new and changed files are copied over the
        network when generating a snapshot.  Remote access is
        implemented securely using ssh.  Unchanged files are stored as
        hard links in the archive and therefore takes virtually no
        space.

        The backups is stored in a directory structure in the format
        YYYY/MM/DD/HH:MM.  Each directory contains a snapshot of the
        backed up directories.  This is stored incrementally by
        letting every file not changed between backups be a hard link
        to the same file in the previous backup.  The actual copying
        is done with rsync.  To avoid typing inn a password you do as
        usual with ssh by generating a public key on the host where
        the backup is stored, read the manual page for ssh, and adding
        this to the list of authorized hosts on the remote computer,
        read the manual page for sshd.

        Which backup to store for how long is configurable, see below.

        The return value is 0 on success and 1 if backing up one of
        the sources failed.

        The destination can not be remote.  If you want to place the
        backup on a remote server, then run Bontmia as a command with
        ssh like "ssh user@host.domain bontmia <options>".

        Use at your own risk.

ARGUMENTS
        --dest <dir> 
                Sets the destination directories where the backups is
                placed.  WARNING! existing files in this directory
                will be DELETED!


OPTIONS
        --source <dir|foo:dir|bar@baz:dir>
                Sets the source directories to backup.  The foo:dir
                and bar@baz:dir notation is for accessing a remote
                host by ssh.

        -d      Will remove old backups but some selected ones.
                See below for the default number of backups to
                save and how to change them.

        --bwlimit <number>
                Specifies a maximum transfer rate in kilobytes per
                second. This option is most effective with large files
                (several megabytes and up). Due to the nature of rsync
                transfers, blocks of data are sent, then if rsync
                determines the transfer was too fast, it will wait
                before sending the next data block. The result is an
                average transfer rate equalling the specified limit. A
                value of zero specifies no limit.  The default is no
                limit.

        --minutes <number>
                Sets the number of backups to save with one per unique
                minute. The default is 3.

        --hours <number>
                Sets the number of backups to save with one per unique
                hour. The default is 24.  The latest backup within the
                hour is saved.

        --days <number>
                Sets the number of backups to save with one per unique
                day. The default is 7.  The latest backup within the
                day is saved.

        --sundays <number>
                This is used as weekly backup.  It sets the number
                of backups to save with one per unique Sunday. The
                default is 4.  The latest backup within the Sunday is
                saved.

        --firstofmonth <number>
                This is used as monthly backup.  Sets the number of
                backups to save with one per unique first of
                month. The default is 12.  The latest backup within
                the first of month is saved.

        --friday13th <number>
                Sets the number of backups to save with one per unique
                Friday the 13th.  The default is 0.  The latest backup
                within the friday13th is saved.


EXAMPLES
        bontmia -d --dest backup --minutes 5 --hours 0 --days 0 \\
                --sundays 0 --firstofmonth 0 --source foo@bar:/baz/zoot

        Here there is made a copy of foo@bar:/baz/zoot in the
        directory backup on the local host.  If this command is run
        every minute, there is store one backup for every minute for
        the last 5 minutes.  If it is run once every day.  There is
        still stored the last 5 backups done at unique minutes so the
        last 5 backups is stored which means 5 last days.

        Hint: set the values for times shorter than the interval used
              when doing backup to 0.


        bontmia -d --dest ./backup --minutes 0 --hours 0 \\
                --source foo@bar:/baz/zoot

        Here there will at the most be stored 7 + 4 + 12 backups
        (minus overlap between the backups).  This can be a good
        command to run nightly.


        bontmia -d --minutes 0 --dest backup
                --source /home/bar/baz foo.no:/var/db

        This is for running every hour.  Remember that only the
        changes is transferred and running more often not necessarily
        will mean copying more data over the network.


        bontmia --dest ./backup --minutes 0 \\
                --source /home/bar/baz foo.no:/var/db

        This backs up but does not care about deleting old backups
        since there is no -d option.


        When bontmia runs it sends output to standard output.  If you
        do not want this you can redirect it to /dev/null.

CONTACT
        Bontmia was written in april 2003 by John Enok Vollestad
        <john.enok@vollestad.no> to merge the functionality of
        glastree and rsync in one application with a more flexible
        selection of long term storage.  It has later undergone some
        bugfixes and enhancements. http://folk.uio.no/johnen/bontmia/

EOF
    exit 1
}


full_name() {
    host="$1";
    if host $host | grep "domain name pointer" >/dev/null; then
	host $host | cut -f5 -d' ' | sed -e 's/\.$//';
    else
	if host $host | grep "has address" >/dev/null; then
	    full_name $(host $host | grep "has address" | cut -f4 -d' ');
	fi;
    fi;
}


filter_template()
{
    attribute="$1"
    grep_value="$2"
    last_number="$3"
    sort_options="$4"

    if test "x$sort_options" != x; then
	sort="sort $sort_options"
    else
	sort="cat"
    fi

    cd "${backup_destination}"
    for archive in */*/*/*; do
	year=$(echo $archive | cut -f1 -d'/')
	month=$(echo $archive | cut -f2 -d'/')
	day=$(echo $archive | cut -f3 -d'/')
	the_clock=$(echo $archive | cut -f4 -d'/')

	the_date=$year-$month-$day
	date --date "$the_date" "+%Y/%m/%d/${the_clock}@${attribute}" || exit 1
    done | grep "@${grep_value}" | sort -r | $sort | tail -${last_number}
}


handle_last_unfinished()
{
    if test -e $backup_destination/unfinished_backup/*; then
	echo
	echo "WARNING: Last backup did not complete."
	echo "  This unfinished backup is now removed."
	echo
    fi
    rm -rf $backup_destination/unfinished_backup
}


make_hard-link_copy_of_last_backup()
{
    last_backup=$(find $backup_destination -maxdepth 4 -mindepth 4 | sort | tail -1)
    if test x$last_backup != x ; then
	mkdir -p $backup_destination/unfinished_backup/$this_backup || exit 1
	echo "Making a hard-link replication of the last backup"
	echo "  ($last_backup)"
	cp -lR $last_backup/* $backup_destination/unfinished_backup/$this_backup
	first="no"
    else
	mkdir -p $backup_destination/unfinished_backup/$this_backup || exit 1
	echo "No previous backup detected, will start with an empty replication"
	first="yes"
    fi
}

moving_complete_backup_into_archive()
{
    mkdir -p "$backup_destination/$this_backup" || exit 1
    echo
    echo "Moving the complete backup into the backup archive"
    echo "  ($backup_destination/unfinished_backup -> $backup_destination/"
    
    mv $backup_destination/unfinished_backup/$this_backup/* $backup_destination/$this_backup/ || exit 1
}

make_backup()
{
    this_backup=$(date +%Y)/$(date +%m)/$(date +%d)/$(date +%H\:%M)

    handle_last_unfinished
    make_hard-link_copy_of_last_backup

    # Apply changes to the hard-link copy
    echo
    if test "x$first" == "xyes"; then
	echo "Backing up."
    else
	echo "Backing up by modifying the replication."
    fi
    for dir in $backup_dirs ; do
	dir_wo_user=$(echo "$dir" | cut -f2- -d'@')
	echo "  ${dir_wo_user}"
	hostname=$(echo -n "$dir" | cut -f2- -d'@' | cut -f1 -d':')":"
	
	if test "x$hostname" == "x$(hostname):"; then
	    # remove hostname from dir to speed up local backup
	    dir=$(echo "$dir" | cut -f2 -d':')
	fi

	mkdir -p "$backup_destination/unfinished_backup/$this_backup/$hostname"
	tenlast=$(rsync ${rsync_options} "${dir}" "${backup_destination}/unfinished_backup/$this_backup/${hostname}" 2>&1 | tail -10) || {
	    echo
	    echo "  Caught an error doing rsync."
	    echo "  The last 10 lines of output from rsync:"
	    echo "$tenlast"
	    echo
	    echo "  Retrying rsync..."
	    tenlast=$(rsync ${rsync_options} "${dir}" "${backup_destination}/unfinished_backup/$this_backup/${hostname}" 2>&1 | tail -10) || {
		echo
		echo "  Still no luck.  Rsync failed while trying to backup"
		echo "  $dir."
		echo "  Please check that there is room for all the data."
		echo "  The last 10 lines of output from rsync:"
		echo "$tenlast"
		echo
		echo
		echo "  Continuing with the next backup source"
		echo
		exit_status="1"
	    }
	}
    done
    
    delete_outside_sync "${backup_destination}/unfinished_backup/$this_backup/"
    
    moving_complete_backup_into_archive
    rm -rf $backup_destination/unfinished_backup
}


delete_old_backup()
{
    echo
    echo "Deleting old backups"

    # by saving the x last, the backups will not be deleted even if no
    # new backups is created

    archives_to_save=$( (

	    if ! test "0$filter_minutes" -ge 0 2>/dev/null; then
		print_usage
	    else
		filter_template "" "" "$filter_minutes" "-u"
	    fi

	    if ! test "0$filter_hours" -ge 0 2>/dev/null; then
		print_usage
	    else
		filter_template "" "" "$filter_hours" "-u --key=1,1 -t :"
	    fi

	    if ! test "0$filter_days" -ge 0 2>/dev/null; then
		print_usage
	    else
		filter_template "" "" "$filter_days" "-u --key=1,3 -t /"
	    fi

	    if ! test "0$filter_sundays" -ge 0 2>/dev/null; then
		print_usage
	    else
		filter_template "%A" "Sunday" "$filter_sundays" "-u --key=1,3 -t /"
	    fi

	    if ! test "0$filter_firstofmonth" -ge 0 2>/dev/null; then
		print_usage
	    else
		filter_template "%A" "Sunday" "$filter_firstofmonth" "-u --key=1,3 -t /"
	    fi

	    if ! test "0$filter_friday13th" -ge 0 2>/dev/null; then
		print_usage
	    else
		filter_template "%A" "Sunday" "$filter_friday13th" "-u --key=1,3 -t /"
	    fi

	) | cut -f1 -d'@' | sort -u)

    cd ${backup_destination}
    for archive in */*/*/*; do
	if ! echo "${archives_to_save}" | grep "^${archive}$" >/dev/null; then
	    echo "  Removing ${backup_destination}/$archive"
	    rm -rf ${archive}
	    rmdir -p $(echo ${archive} | cut -f1-3 -d'/') 2>/dev/null
	else
	    echo "  Saving ${backup_destination}/$archive for now"
	fi
    done
}


delete_outside_sync()
{
    # Since we do a copy from last sync with cp -l, we have to
    # remove the extras here
    echo
    echo "Deletes files that should not be in the latest snapshot"
    cd $1
#    cd $(find $backup_destination -maxdepth 4 -mindepth 4 | sort | tail -1)
    IFS='
'
    for f in $(find -mindepth 1 -depth | egrep -v "$bdirmatch"); do
	#echo "testing $f"
	if test -e "$f" ||
	    test -h "$f"; then
	    rmdir "$f" 2>/dev/null
	    rm -f "$f" 2>/dev/null
	fi
    done
    unset IFS
}


knead_source_path()
{
    source="$1"

    # remove trailing '/'
    if echo "$source" | grep "/$" >/dev/null; then
	source=$(echo "$source" | sed -e 's/\/$//')
    fi
    
    # make the path absolute
    if ! echo "$source" | grep ":" >/dev/null &&
	! echo "$source" | grep "^/" >/dev/null; then
	if echo "$source" | grep "^./" >/dev/null; then
	    source=$(echo "$source" | sed -e 's/^\.\///')
	fi
	source="$current_dir/$source"
    fi

    echo "$source"
}


knead_dest_path()
{
    dest="$1"

    if echo "$dest" | grep ":" >/dev/null; then
	# The destination can not be remote
	print_usage
    fi

    # remove trailing '/'
    if echo "$dest" | grep "/$" >/dev/null; then
	dest=$(echo "$dest" | sed -e 's/\/$//')
    fi

    # make the path absolute
    if ! echo "$dest" | grep "^/" >/dev/null; then
	if echo "$dest" | grep "^./" >/dev/null; then
	    dest=$(echo "$dest" | sed -e 's/^\.\///')
	fi
	dest="$current_dir/$dest"
    fi

    echo "$dest"
}

#################################################################


if test "x$*" == x; then
    print_usage
fi

current_dir=$(pwd)

filter_minutes="3"
filter_hours="24"
filter_days="7"
filter_sundays="4"
filter_firstofmonth="12"
filter_friday13th="0"
bwlimit=""
backup_dirs=""
exit_status="0"
do_del_old="no"

while test "x$*" != x; do
    case "$1" in 
	( "--minutes" )
	    shift
	    filter_minutes="$1"
	    shift;;
	( "--hours" )
	    shift
	    filter_hours="$1"
	    shift;;
	( "--days" )
	    shift
	    filter_days="$1"
	    shift;;
	( "--sundays" )
	    shift
	    filter_sundays="$1"
	    shift;;
	( "--firstofmonth" )
	    shift
	    filter_firstofmonth="$1"
	    shift;;
	( "--friday13th" )
	    shift
	    filter_friday13th="$1"
	    shift;;
	( "--bwlimit" )
	    shift
	    bwlimit="--bwlimit=$1"
	    shift;;
	( "-d" )
	    do_del_old="yes";
	    shift;;
	( "--dest" )
	    shift;
	    backup_destination="$(knead_dest_path "$1")";
	    if ! test -d "$1"; then
		echo "Destination dir $backup_destination does not exist or is not a directory"
		exit 1
	    fi
	    shift;;
	( "--source" )
	    shift
	    if test "x$1" == "x"; then
		echo "Missing source directories"
		exit 1
	    fi
	    backup_dirs=""
	    while test "x$*" != x; do
		dir="$1"
		if ! echo "$dir" | grep ":" >/dev/null; then
		    remotehost="$(hostname)"
		    dir="$remotehost:$(knead_source_path "$dir")"
		else
		    backuppath="$(echo "$dir" | cut -f2- -d':')"
		    if echo "$dir" | grep "@" >/dev/null; then
			remotehost=$(echo "$dir" | cut -f1 -d':' | cut -f2 -d'@')
			remoteuser=$(echo "$dir" | cut -f1 -d':' | cut -f1 -d'@')
		    else
			remotehost=$(echo "$dir" | cut -f1 -d':')
			remoteuser="$(whoami)"
		    fi

		    remotehost=$(full_name $remotehost)

		    if echo "$dir" | cut -f2- -d':' | grep "^/" >/dev/null; then
			abolutepart=""
		    else
			absolutepart=$(ssh $remotehost pwd)"/"
		    fi
	
		    dir="$remoteuser@$remotehost:$absolutepart$backuppath"
		fi
		backup_dirs="$backup_dirs $(knead_source_path "$dir")"
		shift
	    done;;
	( * )
	    print_usage
	    exit 1;;
    esac
done


tmpdir="$backup_destination"

rsync_options="-azv -T $tmpdir --force --relative -e ssh --hard-links --delete $bwlimit" # --stats"

# to speed up checking for files outside the backup areas
bdirmatch=$(
    first="yes"
    echo -n "^("
    for d in $backup_dirs; do
	dir="$d"
	if test "$first" == "yes"; then
	    if echo "$dir" | grep ":" >/dev/null; then
		dir_wo_user=$(echo "$dir" | cut -f2- -d'@')
		echo -n "./$dir_wo_user/"
	    else
		echo -n ".$dir/"
	    fi
	    first="no"
	else
	    if echo "$dir" | grep ":" >/dev/null; then
		dir_wo_user=$(echo "$dir" | cut -f2- -d'@')
		echo -n "|./$dir_wo_user/"
	    else
		echo -n "|.$dir/"
	    fi
	fi
    done
    echo -n ")"
)


if test "x$backup_dirs" != x; then
    make_backup
fi

if test "x$do_del_old" == xyes; then
    delete_old_backup
fi

exit $exit_status
